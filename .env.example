# Gmail API Credentials
GMAIL_CREDENTIALS_FILE=config/gmail_credentials.json
GMAIL_TOKEN_FILE=config/gmail_token.json

# ============================================================================
# LLM Configuration - Choose ONE configuration below
# ============================================================================

# OPTION 1: Together.ai (RECOMMENDED FOR DEVELOPMENT)
# Fast, reliable, cost-effective hosted inference
# Sign up at: https://api.together.xyz/
# Pricing: ~$0.20 per 1M tokens (very cheap for email classification)
LLM_BASE_URL=https://api.together.xyz/v1
LLM_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
LLM_API_KEY=your-together-api-key-here

# OPTION 2: Local MLX Server (RECOMMENDED FOR PRODUCTION)
# Runs on your macOS laptop with Apple Silicon
# Free, private, fast inference
# See docs/mlx_server_setup.md for setup instructions
# LLM_BASE_URL=http://localhost:8080/v1
# LLM_MODEL=mlx-community/Llama-3.2-3B-Instruct-4bit
# LLM_API_KEY=not-needed

# OPTION 3: OpenAI (ALTERNATIVE)
# Most expensive option, but highest quality
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4o-mini
# LLM_API_KEY=your-openai-api-key-here

# ============================================================================
# Quick Start Guide:
# ============================================================================
# DEVELOPMENT (in Codespaces/Linux):
#   1. Sign up for Together.ai account
#   2. Get API key from https://api.together.xyz/settings/api-keys
#   3. Use OPTION 1 above (Together.ai)
#   4. Set LLM_API_KEY to your Together.ai key
#
# PRODUCTION (on macOS laptop):
#   1. Set up MLX server (see docs/mlx_server_setup.md)
#   2. Start server: mlx_lm.server --model mlx-community/Llama-3.2-3B-Instruct-4bit
#   3. Use OPTION 2 above (Local MLX)
#   4. Set LLM_BASE_URL=http://localhost:8080/v1
# ============================================================================

# Label Configuration
LABEL_CONFIG_FILE=config/labels.json

# Logging
LOG_LEVEL=INFO
LOG_FILE=data/logs/email_triage.log
